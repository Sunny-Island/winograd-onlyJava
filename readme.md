## 组员
* 赵家贝 清华大学软件学院研二
* 谭新宇 清华大学软件学院研二 tanxinyu@apache.org
* 宋一唱 清华大学软件学院研二

## 配置环境

	a. 需要包含测试平台的硬件、软件环境信息，保证可复现性；

## 第一题：Winograd
###　特性分析
- 缓存命中缓存一致性
### 优化思路
- 并行
卷积运算的过程是可以进行并行计算的，比如示例代码中给出的计算中，每一个 channel 的计算就是完全互不干扰，可以并行的。要想加速卷积运算，需要充分利用计算平台多核的优势，尽可能在每一个环节把计算并行化。我们在算法中通过 openmp 库，进行了并行计算的尝试。

- SIMD/向量化
单指令流多数据流（英语：Single Instruction Multiple Data，缩写：SIMD）是基于硬件的支持，微处理器中一个控制器可以控制多个平行的处理微元，对一组数据（数据向量）进行计算，是一种常用于加速计算密集的并行任务的优化方法。
1997 年，x86 扩展出了 MMX 指令集，伴随着 80-bit 的 vector 寄存器，首开向量化计算的先河。 之后，x86 又扩展出了 SSE 和 AVX 指令集。SSE 和 AVX 各有 16 个寄存器。SSE 的 16 个寄存器为 XMM0-XMM15，AVX 的 16 个寄存器为 YMM0-YMM15。同一个寄存器可以装载多个 float 数，并且可以用相应的指令同时进行运算。在我们的服务器和赛方提供的服务器上，我们依次实验了 AVX128，AVX256 和 AVX512 指令集。
算法优化
本题中采用的 Winograd 算法是一种减少乘法次数，增加加法次数，从而对矩阵乘法加速的算法。在示例代码中的 winograd 算法实际上是一种一维算法，需要逐个对每个图片每个 channel 的每一行每一列与每个卷积核相乘，因此有大量的 for 循环。通过查阅文献，我们发现在 3D 卷积运算中，相对于示例代码我们可以做出三个优化：
  - 转换 1D 的 winograd 算法到 2D。比如示例的 winograd(2,3) 可以转换成 winograd(2x2,, 3x3), 可以同时计算得到一个 (2x2) 的输出。
  - 转换 1D 的 winograd 算法到 3D。相关文献指出，在 3D 的矩阵运算中，可以把 winograd 算法分成 4 步，分别是 Input transform、Filter transform、Matrix Multiplication、Output transform。
![](https://s2.ax1x.com/2019/04/29/E1qSoR.png)
  - 扩展 winograd(2,3) 算法到 winograd(4,3)。根据相关文献指出，4x3 算法能更多地减少乘法运算的比例，从而带来更好的加速效果。而且 4x3 将矩阵分块更大一些，对增加缓存命中也相对友好。

根据文献的实验结果，3D-winograd(2,3) 算法是最节能的，适合在 FPGA 等边缘设备上部署。但 3D-winograd(4,3) 算法前向传播是最快的，因此我们最终采取了 3D-winograd(4,3) 算法。

- 缓存/cache miss
在计算密集的并行计算中，要尽可能地利用好缓存，精心设计程序以减少缓存到内存的数据读取。同时多线程的环境下还会出现伪共享问题，大大降低程序的性能。

# 实现/工程细节
- 缓存

在优化时，我们按照程序中的提示，先从优化矩阵计算出发。示例代码的矩阵运算显然是一种对缓存的低效利用，每次读取一段内存，但只用到了其中的第一个数据，下次循环又要去读取新的内存。通过交换循环的顺序，即可提升对缓存的利用效率。我们对矩阵乘法运算做了如下的改进，程序性能就有了 10 倍的提升 (0.22GFlops->3.05GFlops)。

- simd avx128

把矩阵运算划分成一部分 4x4 矩阵运算，不能被 4 整除的部分单独做 1x1 的矩阵运算。并通过 SIMD-avx128 指令集计算 4x4 矩阵运算，在 avx128 中一个寄存器可以存储 4 个 float 数，也可以同时对 4 的 float 做向量化计算。在 4x4 的运算中没有循环，全部做循环展开做计算。同时加入 fma 指令集引入积和熔加运算，进一步压缩指令。此处优化有近 6 倍的提升 (3.05GFlops->12.88 GFlops)

- 多线程 无效到有效 分配
  
此时，我们尝试通过引入 openmp 多线程进行矩阵运算，但多线程一直有负优化的效果，甚至经过实验发现有线程数加倍性能减半的现象。经过分析发现在示例代码中有大量的小矩阵运算，比如在第一部分逐 channel 逐卷积核的矩阵相乘中有大量的大小为 4 的矩阵，矩阵太小导致分给每个线程的任务过少，线程本身的开销大于多线程带来的收益，因此多线程在这种运算中是一种负优化。

为了引入并行加快速度，我们单独为中间的大矩阵运算编写了加入了多线程的函数，小矩阵运算则不加多线程。这一调整有近 5 倍的提升。(12.88GFlops->57.11GFlops)

- perf 调优，寻找瓶颈
此时，我们通过 perf 查看程序各部分的耗时分布。发现如下的问题：
	- 矩阵初始化耗时过长，应该改为 memset，这一调整有 3%的提升 (57.11GFlops->60.86GFlops)
	- winograd 函数中大矩阵计算前后的两个部分耗时过长，这一部分属于算法设计问题，应该对整个算法进行调整。
  
- 加入 avx256
此时我们更换了一台支持 avx2 指令集的服务器同时指令集换成 avx256，在 avx256 中每个寄存器可以存储 8 个 float 数，因此将原来 4x4 矩阵运算更换成 8x8 矩阵运算，这一调整有 1.5 倍的提升 (60.86GFlops->97GFlops)。

编译器优化
llvm gcc 尝试 (97-106GFlops)

升级到 avx512 win4x3 优化 && 3d 矩阵乘法优化

最终在赛方提供的服务器上，我们重新写了 winograd 算法，更新成 3D-winograd(4x3) 算法。在这里，我们分四个部分详细介绍该算法的实现
- Input transform

首先把输入矩阵拆分成 tiles，在这里 tiles 是长宽均为 6 的矩阵，在拆分过程中为了充分发挥向量化的作用，每一次会同时对 16 个 6x6 的 tile 矩阵进行操作，因为每个 avx512 寄存器能存储 16 个 float 数。通过循环展开手写 avx 指令的方式，把 16 个矩阵中的数读取出来并重新排列，之后再批量与矩阵 G 相乘，相乘操作也全部展开用 avx 指令的方式实现。这样批量操作可以充分发挥单核 SIMD 指令的效能，并且每个计算单元不会影响其他部分的内存，不会出现伪共享问题，可以实现完全的并行操作。大量的循环展开虽然增加了代码量，但有利于减少循环开销、也有利于指令流水线的调度。对于边长不满足被步长整除（步长为 4/64，即无法被 4/64 整除）的参数，可以进行 padding。
- Filter transform
因为卷积核是固定的 3x3 大小，SIMD 无法发挥作用，因此这里使用了循环展开和多线程进行计算卷积核与矩阵 G 相乘，因为卷积核之间也是互相独立的，因此可以尽可能的增加并行度加快运算。最后的赋值也使用#pragma unroll 指示编译器进行循环展开。

- Matrix Multiplication

经过测试发现，使用 mkl 替换我们自己的矩阵有较大的提升（约 3 倍提升），因此这里全部替换成 mkl 的 sgemm 函数。这里的并行度有两个参数，一个是 36，因为经过 Input transform 得到的三维矩阵有一维是 36，且彼此之间互不影响，可以独立并行。另一个参数是 batch，因为之前把 batch 中所有图像拼在了一起，这里也可以并行，相当于对每个图像做计算。

- Output transform

与 Input transform 类似，也是对 16 个 6x6 的 tile 矩阵进行操作，最终与矩阵 A 相乘，得到 16 个 4x4 的矩阵，并保存到结果矩阵中。这里也大量使用 avx 指令进行循环展开，并在函数外层使用 openmp 多线程对不同区域进行操作。

这一步的优化包括算法优化、指令集优化，并且引入了 MKL 替代原来的矩阵乘法。在算法实现方面注意调整内存的分布，尽量提高缓存命中；尽量使用循环展开，用代码量和可读性换性能；通过分 tile、分块操作的方法，将算法分割成一个个独立的部分，在保证正确性的前提下尽量提高并行度。这些操作提升了 13 倍左右 (170GFlops->2200GFlops)

最后的性能，编译指令

## 参考资料
https://zhuanlan.zhihu.com/p/72953129

## 第二题：H5bench

### 如何测得正确的带宽

### 优化方法
async 分块 压缩 多进程

## 总结
